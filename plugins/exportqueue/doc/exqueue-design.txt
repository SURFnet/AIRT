Design of the AIRT Export Queue
===============================================================================
$Id$

BLOCKS BETWEEN *** STILL NEED TO BE REFINED


The AIRT Export Queue is a mechanism to asynchronously call external
programs from within the AIRT interface. Async calls are interesting when
the external program takes longer than a few seconds to execute, and thus a
synchronous call would be impractical. Typical external async calls are for
a nmap/Nessus run, which could take hours to complete. An additional feature
is that the export queue can run external programs as a different user than
the web server user (typically "www-data").


AIRT User Interface
-------------------
External programs can be called up in the AIRT interface from two places:
outside an incident (side menu or main menu) and inside an incident
(incident details page). The difference is that the former never has any
context, while the latter can provide some context data from the incident
record and a limited option to feed the results of the external program back
to the incident record.

External programs can be dynamically parametrized from AIRT. A simple
mechanism is provided to generate a parameter string with limited variable
expansion from the AIRT incident record data. For the moment, more extensive
mechanisms including full HTML entry forms are not implemented, but these
can be added later without much fuss.


AIRT System Interface
---------------------
The Export Queue is a mechanism which provides a single, clean access point
to external programs from within AIRT, together with a basic option for data
passthrough which might be of interest to the external program.

AIRT uses as much of the operating system as possible to implement the
external program queue. The AIRT part is limited to a bit of administration
of queued, running, and completed jobs, plus a narrow interface to and from
the free-running external programs. A fundamental design issue was to fully
separate the external program code and environment from the AIRT system.
Especially for programs such as nmap which tend to require to be run as
root, such a paranoid approach really is required.

The narrow channel between AIRT and the external program allows for a simple
one-line parameter string that is passed to the program. With the external
program forked off asynchronously, the options it has to send the result
back to AIRT are limited. As part of the parameter string, it will receive a
fully specified file name to which it may write a single line of result,
which should start with OK, WARNING or ERROR, followed by a maximum of 80
characters in flat ASCII. For AIRT, the reception of this file marks the end
of the exported task. It only serves as a commented flag. AIRT does not
process the results in any way, it just stores them in the export queue to
flag the completion of the task.

If the external program has more than just a one-liner to report back to
AIRT, it must do so via the import mechanism, creating a new incident. AIRT
does not provide extra help except for what the import mechanism already
offers.


Incident Context
----------------
***
- Some basic incident data.
- Entry in the incident history.
- AIRT event handling?
- Possibly, list of pending tasks per incident.
- Expiration/warning mechanism.

A function should be available which can produce a parameter string using
standard %x expansion. Hm. Inside AIRT, this won't do, as nobody except the
AIRT developers is supposed to touch this code. A better solution seems to
be to define what parameter string is fed to the external program (wrapper
script), and keep this string extensible. The database and whole export
queue mechanism should already be built with this in mind. In other words,
the AIRT core function export_Foepie() should produce a string which is
passed on to the wrapper script unparsed by anything. Only the queue itself
might add the queue item ID.
***


AIRT Interface Design
---------------------
***
- Mechanism to dynamically compile a parametrized URL.
- Mechanism to securely catch parametrized URLs.
- Narrow call channel for external program scripts.
- Single list (directory) with callable scripts.
- Predefined format for such scripts, using start-stop-daemon for the
  actual queue work.
***


Operating System Interface
--------------------------
Several important issues need to be adressed by the OS interface, notably
the fully asynchronous execution of a non-AIRT program, the switching to
another user (not the web server ("www-data") user), and the handling of
standard system housekeeping tasks such as security and resource management.
AIRT explicitly does not try to shield itself from the external programs.
This separation is fully in the hands of the OS, and therefore in the hands
of the OS administrator, who does not need to trust any AIRT code.

AIRT uses the system batch job facility, known as cron. An AIRT-provided PHP
script in CLI mode is run every n minutes via a standard entry in
/etc/cron.d/airt . The system administrator determines how often (typically
once per minute) and as which user (typically "airtexport") this script is
run.

The cron script accesses the AIRT core database and picks up exported tasks
that are ready to be run. These tasks must be available as an executable in
a predefined directory, usually /usr/local/share/airt/lib/exportqueue, as
they are site-specific. If the correct executable can be found, it is forked
off with the parameter string from the database, and the cron script logs
this event back to the AIRT core database. The cron script then terminates
and will run again when cron fires.

The site-specific executables in /usr/local/share/airt/lib/exportqueue are
usually wrappers around standard programs such as nmap. The wrapper sets up
a working environment for the actual work horse, including a sudo statement
if required. If output of the work horse needs to be retained for reporting,
it should be sent to files, but the wrapper script is responsible for
housekeeping. If extensive results are to be sent to AIRT, the wrapper needs
to call the airt_import program with the proper filter. After everything is
said and done, the wrapper is expected to call airt_export again with the
--done parameter, sending its task ID, exit status, and a plain text message
back to the AIRT export queue. For additional security, the task ID is not
sent as a predictable string, but as a one-way hash that needs to be
returned verbatim.

If an external program crashes and is not able to send the exit status back
to the export queue, the job will remain flagged as "started at ..." until
the export queue is purged. AIRT is robust against this, but does not take
actions to determine why the process crashed.

***
What data do we need to start up a background/export process?

- Which user we want to run the actual process. This is determined fully by
  the site-specific wrapper script.
- Which ID this process has, so that we can refer to it and put the results
  back into the export queue after job completion.
- Which main program we need (nmap, Nessus, router control...). Not a true
  executable name, but a wrapper script name in the exportqueue directory.
- Parameters for the wrapper script, such as IP address and scan type. Fully
  dependent on the wrapper script.
- Optionally a delayed start time for advanced scheduling (cheap). Default
  should be "as soon as possible", i.e., the next whole minute.
***


FILE SYSTEM STRUCTURES AND FHS

We follow the Filesystem Hierarchy Standard (http://www.pathname.com/fhs/)
as closely as possible to keep AIRT portable to a wide range of Unix
systems.

Everything that is specific to AIRT must go in /var/lib/airt (via the
%STATEDIR% install-time variable). This includes all input and output files
for the external programs, as far as they are interesting. Non-interesting
files may go to /[var/]tmp or /dev/null instead.

If any external program needs a lock file, it should go to /var/lock, which
is accessible to any user. This is to prevent clashes when the same program
is run outside the AIRT scope. AIRT does not know of this, it is up to the
site-specific wrapper script to use this mechanism.

External program log files should be avoided if possible, but if they are
required and do not fall under the input/output files of the program which
go to %STATEDIR%, they can be dropped in /var/log. Note that this usually
requires a specific setup, as /var/log itself is only accessible by root.
Consider /var/tmp, /tmp, or /dev/null instead.

The /var/run directory is also only accessible by root and therefore should
be avoided to store PIDs and other state info. Although it may be the system
itself that started a program (via the cron job), the program should be seen
as running under command of AIRT and the state files should go to
%STATEDIR%. The same holds for /var/spool.

Non-living files (read-only, except when (re)configuring AIRT) go to the
standard /etc/airt/ tree if they are true config files (no code, only
defines and includes), to the standard /usr/share/airt/lib for code that
shipped with the core, and to /usr/local/share/airt/lib/exportqueue for code
specific to the exportqueue plugin, such as site-specific extensions
(wrapper scripts).


AIRT CONTEXT

***
- Firing off an external program might lead to an event registration for the
  associated incident. This adds a history line, nothing more. A returned
  answer may also lead to a history line. There are no other options to add
  a result to an incident.
***


USER INTERACTION BEFORE FIRING OFF

If a user form must be shown before the export queue entry is made, the site
administrator must provide this form. It does not seem a good idea at this
moment to allow a full HTML/PHP page for a form, with the associated data
catcher and all fuss. We might get away with a simple list of variable names
that gets expanded into a simple form, and leads to a parameter line with a
'--variable=value --variable=value --variable=value' structure. Later.


AIRT DATABASE SCHEMA EXTENSION

The export queue has a few database structures to manage and administer the
starting and stopping/cleaning up of background tasks. Purpose of the table
is to hold tasks to be started, tasks that have been started and are
supposedly running now, tasks that have completed and returned results, and
tasks that might have died without returning a result.

CREATE TABLE export_queue (
  id        integer;
  task      varchar(32)   not null,
  params    varchar(256),
  created   timestamp     not null,
  scheduled timestamp,
  started   timestamp,
  ended     timestamp,
  result    varchar(256),
  primary key (id)
)

The airt_export program queries the table and selects tasks with both a
"scheduled" time that has passed and no "started" time. These are started by
forking off the "task" wrapper script with the "-output <filename>"
parameter and the "params" string broken up in pieces. Start time is also
recorded. When a return string is found, ended time is recorded and the
string is stored in the table. A purge thing should remove ended tasks of 24
hours old, or so.


LOOSE ENDS

Useful PHP man page:
http://nl2.php.net/manual/en/function.shell-exec.php
Look for the contribution by jesuse dot gonzalez at venalum dot com dot ve.
Alternatively look at http://nl2.php.net/manual/en/function.pcntl-fork.php

[EOF]
